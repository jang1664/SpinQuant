{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f8c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = [\n",
    "  \"python\",\n",
    "  \"--input_model\", \"llama2-7b-atlas2\",\n",
    "  \"--do_train\", \"False\",\n",
    "  \"--do_eval\", \"True\",\n",
    "  \"--per_device_eval_batch_size\", \"4\",\n",
    "  \"--model_max_length\", \"2048\",\n",
    "  \"--fp16\", \"True\",\n",
    "  \"--bf16\", \"False\",\n",
    "  \"--save_safetensors\", \"False\",\n",
    "  \"--w_bits\", \"4\",\n",
    "  \"--a_bits\", \"16\",\n",
    "  \"--k_bits\", \"4\",\n",
    "  \"--v_bits\", \"4\",\n",
    "  \"--w_clip\",\n",
    "  \"--a_asym\",\n",
    "  \"--k_asym\",\n",
    "  \"--v_asym\",\n",
    "  \"--k_groupsize\", \"128\",\n",
    "  \"--v_groupsize\", \"128\",\n",
    "  \"--rotate\",\n",
    "  \"--save_qmodel_path\", \"saved_models/qllama2-7b-4-4-4-128-fp16.pt\",\n",
    "  \"--optimized_rotation_path\", \"rotation_llama-2-7b/a4w4kv4_fp16/R.bin\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc8fd688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "820943a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from logging import Logger\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from transformers import LlamaTokenizerFast\n",
    "import transformers\n",
    "from eval_utils.main import ptq_model\n",
    "from eval_utils.modeling_llama import LlamaForCausalLM\n",
    "from utils import data_utils, eval_utils, utils\n",
    "from utils.process_args import process_args_ptq\n",
    "\n",
    "log: Logger = utils.get_logger(\"spinquant\")\n",
    "\n",
    "import evaluate\n",
    "from lm_eval import evaluator\n",
    "from lm_eval.utils import make_table\n",
    "\n",
    "from utils.quant_utils import find_qlayers, ActQuantWrapper\n",
    "from functools import partial\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9be3ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_names = ['hellaswag', 'arc_easy','arc_challenge', 'winogrande', 'openbookqa', \"wikitext\"]\n",
    "# task_names = ['openbookqa']\n",
    "# task_names = ['arc_easy']\n",
    "\n",
    "CUDA_DEVICES = list(map(str.strip, os.environ.get(\"CUDA_VISIBLE_DEVICES\", \"0\").split(\",\")))\n",
    "FIRST_GPU_ID = int(CUDA_DEVICES[0])\n",
    "GPU_ID = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ddef668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- ARGS ----------\n",
      "-----model args-----\n",
      "ModelArguments(input_model='llama2-7b-atlas2', output_rotation_path='test-output', optimized_rotation_path='rotation_llama-2-7b/a4w4kv4_fp16/R.bin', access_token=None)\n",
      "------train args-------\n",
      "TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "cache_dir=None,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=no,\n",
      "eval_use_gather_object=False,\n",
      "evaluation_strategy=None,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/output/runs/May12_14-59-53_atlas2,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "model_max_length=2048,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=/tmp/output/,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/output/,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=False,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "-------- ptq args ---------\n",
      "Namespace(seed=0, rotate=True, rotate_mode='hadamard', rotation_seed=-1, fp32_had=False, a_bits=16, a_groupsize=-1, a_asym=True, a_clip_ratio=1.0, w_bits=4, w_groupsize=-1, w_asym=False, w_rtn=False, w_clip=True, nsamples=128, percdamp=0.01, act_order=False, int8_down_proj=False, v_bits=4, v_groupsize=128, v_asym=True, v_clip_ratio=1.0, k_bits=4, k_groupsize=128, k_asym=True, k_pre_rope=False, k_clip_ratio=1.0, load_qmodel_path=None, save_qmodel_path='saved_models/qllama2-7b-4-4-4-128-fp16.pt', export_to_et=False, capture_layer_io=False, layer_idx=10, optimized_rotation_path='rotation_llama-2-7b/a4w4kv4_fp16/R.bin', bsz=4)\n",
      "------- ARGS END ----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192a3cb866d74ad69f67069b03f50d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rotating:  28%|██▊       | 9/32 [00:52<02:15,  5.88s/layer]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m     model\u001b[38;5;241m.\u001b[39mlm_head\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39membed_tokens\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 36\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mptq_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mptq_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# for l, layer in enumerate(model.model.layers):\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#     layer.self_attn.q_proj.quantizer.register_forward_hook(partial(forward_hook_act_quant, name=name))\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#     layer.self_attn.q_proj.register_forward_hook(forward_hook_weight_quant)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m model\u001b[38;5;241m.\u001b[39mseqlen \u001b[38;5;241m=\u001b[39m training_args\u001b[38;5;241m.\u001b[39mmodel_max_length\n",
      "File \u001b[0;32m~/project.local/SpinQuant/eval_utils/main.py:27\u001b[0m, in \u001b[0;36mptq_model\u001b[0;34m(args, model, model_args)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mrotate:\n\u001b[1;32m     26\u001b[0m     fuse_norm_utils\u001b[38;5;241m.\u001b[39mfuse_layer_norms(model)\n\u001b[0;32m---> 27\u001b[0m     \u001b[43mrotation_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     utils\u001b[38;5;241m.\u001b[39mcleanup_memory(verbos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     30\u001b[0m     quant_utils\u001b[38;5;241m.\u001b[39madd_actquant(model)  \u001b[38;5;66;03m# Add Activation Wrapper to the model\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/spinquant/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project.local/SpinQuant/eval_utils/rotation_utils.py:143\u001b[0m, in \u001b[0;36mrotate_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     R2 \u001b[38;5;241m=\u001b[39m get_orthogonal_matrix(head_dim, args\u001b[38;5;241m.\u001b[39mrotate_mode)\n\u001b[0;32m--> 143\u001b[0m \u001b[43mrotate_attention_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m rotate_attention_output(layers[idx], R1)\n\u001b[1;32m    145\u001b[0m rotate_mlp_input(layers[idx], R1)\n",
      "File \u001b[0;32m~/project.local/SpinQuant/eval_utils/rotation_utils.py:68\u001b[0m, in \u001b[0;36mrotate_attention_inputs\u001b[0;34m(layer, R1)\u001b[0m\n\u001b[1;32m     66\u001b[0m dtype \u001b[38;5;241m=\u001b[39m W\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m     67\u001b[0m W_ \u001b[38;5;241m=\u001b[39m W\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m---> 68\u001b[0m W\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# dist.init_process_group(backend=\"nccl\", timeout=datetime.timedelta(hours=8))\n",
    "model_args, training_args, ptq_args = process_args_ptq()\n",
    "print(\"------- ARGS ----------\")\n",
    "print(\"-----model args-----\")\n",
    "print(model_args)\n",
    "print(\"------train args-------\")\n",
    "print(training_args)\n",
    "print(\"-------- ptq args ---------\")\n",
    "print(ptq_args)\n",
    "print(\"------- ARGS END ----------\")\n",
    "\n",
    "# local_rank = utils.get_local_rank()\n",
    "\n",
    "# log.info(\"the rank is {}\".format(local_rank))\n",
    "# torch.distributed.barrier()\n",
    "\n",
    "config = transformers.AutoConfig.from_pretrained(\n",
    "    model_args.input_model, token=model_args.access_token\n",
    ")\n",
    "# Llama v3.2 specific: Spinquant is not compatiable with tie_word_embeddings, clone lm_head from embed_tokens\n",
    "process_word_embeddings = False\n",
    "if config.tie_word_embeddings:\n",
    "    config.tie_word_embeddings = False\n",
    "    process_word_embeddings = True\n",
    "dtype = torch.bfloat16 if training_args.bf16 else torch.float16\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_args.input_model,\n",
    "    config=config,\n",
    "    torch_dtype=dtype,\n",
    "    token=model_args.access_token,\n",
    ")\n",
    "if process_word_embeddings:\n",
    "    model.lm_head.weight.data = model.model.embed_tokens.weight.data.clone()\n",
    "model.cuda()\n",
    "\n",
    "model = ptq_model(ptq_args, model, model_args)\n",
    "\n",
    "# for l, layer in enumerate(model.model.layers):\n",
    "#     layer.self_attn.q_proj.quantizer.register_forward_hook(partial(forward_hook_act_quant, name=name))\n",
    "#     layer.self_attn.q_proj.register_forward_hook(forward_hook_weight_quant)\n",
    "\n",
    "model.seqlen = training_args.model_max_length\n",
    "# if local_rank == 0:\n",
    "log.info(\"Model PTQ completed {}\".format(model))\n",
    "log.info(\"Start to load tokenizer...\")\n",
    "tokenizer = LlamaTokenizerFast.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_args.input_model,\n",
    "    cache_dir=training_args.cache_dir,\n",
    "    model_max_length=training_args.model_max_length,\n",
    "    padding_side=\"right\",\n",
    "    use_fast=True,\n",
    "    add_eos_token=False,\n",
    "    add_bos_token=False,\n",
    "    token=model_args.access_token,\n",
    ")\n",
    "log.info(\"Complete tokenizer loading...\")\n",
    "model.config.use_cache = False\n",
    "\n",
    "# dataset_ppl = eval_utils.evaluator(model, testloader, utils.DEV, ptq_args)\n",
    "# log.info(\"wiki2 ppl is: {}\".format(dataset_ppl))\n",
    "# dist.barrier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826c45e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "05ac1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Hey, are you conscious? Can you talk to me?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs.input_ids = inputs.input_ids.cuda()\n",
    "inputs.attention_mask = inputs.attention_mask.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "213d832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[', I you going?\\n you hear to me?\\n']\n"
     ]
    }
   ],
   "source": [
    "# forward\n",
    "output = model(\n",
    "  input_ids=inputs.input_ids,\n",
    "  use_cache=True\n",
    ")\n",
    "next_tokens = torch.argmax(output.logits, dim=-1)\n",
    "result = tokenizer.batch_decode(next_tokens, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "681a1b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Hey, how are you?\"\n",
    "inputs_2 = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs_2.input_ids = inputs_2.input_ids.cuda()\n",
    "inputs_2.attention_mask = inputs_2.attention_mask.cuda()\n",
    "\n",
    "# inputs.input_ids = torch.cat([inputs.input_ids, inputs_2.input_ids], dim=1)\n",
    "# inputs.attention_mask = torch.cat([inputs.attention_mask, inputs_2.attention_mask], dim=1)\n",
    "past_key_values = output.past_key_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "785f3822",
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = model(\n",
    "  input_ids=inputs_2.input_ids, use_cache=True, past_key_values=past_key_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f342ced1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[', are are you feeling\\n']\n"
     ]
    }
   ],
   "source": [
    "next_tokens2 = torch.argmax(output2.logits, dim=-1)\n",
    "result2 = tokenizer.batch_decode(next_tokens2, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ea5fb82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, are you conscious? Can you talk to me?\n",
      "I was able to answer, \"Yes, I am conscious.\"\n",
      "The doctor said, \"Well, that's good. Now, can you talk to me?\"\n",
      "I said, \"Yes, I can talk to you.\"\n",
      "The doctor said, \"Well, that's good. Now, can you hear me?\"\n",
      "I said, \"Yes, I can hear you.\"\n",
      "The doctor said, \"Well, that's good. Now, can you move?\"\n",
      "I said, \"Yes, I can move.\"\n",
      "The doctor said, \"Well, that's good. Now, can you stand?\"\n",
      "I said, \"Yes, I can stand.\"\n",
      "The doctor said, \"Well, that's good. Now, can you sit?\"\n",
      "I said, \"Yes, I can sit.\"\n",
      "The doctor said, \"Well, that's good. Now, can you lie down?\"\n",
      "I said, \"Yes, I can lie down.\"\n",
      "The doctor said, \"Well, that's good. Now, can you get up?\"\n",
      "I said, \"Yes, I can get up.\"\n",
      "The doctor said, \"Well, that's good. Now, can you get out of bed?\"\n",
      "I said, \"Yes, I can get out of bed.\"\n",
      "The doctor said, \"Well, that's good. Now, can you get downstairs?\"\n",
      "I said, \"Yes, I can get downstairs.\"\n",
      "The doctor said, \"Well, that's good. Now, can you get down the street?\"\n",
      "I said, \"Yes, I can get down the street.\"\n",
      "The doctor said, \"Well, that's good. Now, can you get to the hospital?\"\n",
      "I said, \"Yes, I can get to the hospital.\"\n",
      "The doctor said, \"Well, that's good. Now, can you get to the doctor?\"\n",
      "I said, \"Yes, I can get to the doctor.\"\n",
      "The doctor said, \"Well, that's good. Now, can you get to the operating room?\"\n",
      "I said, \"Yes, I can get to the operating room.\"\n",
      "The doctor said, \"Well, that's good. Now, can you get to the operating table?\"\n",
      "I said, \"Yes, I can get to the operating table.\"\n",
      "The doctor said, \"Well, that's good. Now, can you get on the operating table?\"\n",
      "I said, \"Yes, I can get on the operating table.\"\n",
      "The doctor said, \"Well, that's good. Now, can you lie down on the operating table?\"\n",
      "I said, \"Yes, I can lie down on the operating table.\"\n",
      "The doctor said, \"Well, that's good. Now, can you roll over on the operating table?\"\n",
      "I said, \"Yes, I can roll over on the operating table.\"\n",
      "The doctor said, \"Well, that's good. Now, can you turn over on the operating table?\"\n",
      "I said, \"Yes, I can turn over on the operating table.\"\n",
      "The doctor said, \"Well, that's good. Now, can you get off the operating table?\"\n",
      "I said, \"Yes, I can get off the operating table.\"\n",
      "The doctor said, \"Well, that's good. Now, can you get up from the operating table?\"\n",
      "I said, \"Yes, I can get up from the operating table.\"\n",
      "The doctor said, \"Well, that's good. Now, can you get dressed?\"\n",
      "I said, \"Yes, I can get dressed.\"\n",
      "The doctor said, \"Well, that's good. Now, can you get dressed and walk?\"\n",
      "I said, \"Yes, I can get dressed and walk.\"\n",
      "The doctor said, \"Well, that's good. Now, can you get dressed and walk out of the hospital?\"\n",
      "I said, \"Yes, I can get dressed and walk out of the hospital.\"\n",
      "The doctor said, \"Well, that's good. Now, can you get dressed and walk to your car?\"\n",
      "I said, \"Yes, I can get dressed and walk to my car.\"\n",
      "The doctor said, \"Well, that's good. Now, can you get dressed and drive?\"\n",
      "I said, \"Yes, I can get dressed and drive.\"\n",
      "The doctor said, \"Well, that's good. Now, can you get dressed and drive to your house?\"\n",
      "I said, \"Yes, I can get dressed and drive to my house.\"\n",
      "The doctor said, \"Well, that's good. Now, can you get dressed and drive into your garage?\"\n",
      "I said, \"Yes, I can get dressed and drive into my garage.\"\n",
      "The doctor said, \"Well, that'\n"
     ]
    }
   ],
   "source": [
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=1024)\n",
    "result = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9eec6cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(1, 128, dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "efbe9170",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.nn.SiLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "359fd862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.0869e-01, 3.0933e-01, 8.8440e-02, 3.5791e-01, 7.2205e-02, 6.7041e-01,\n",
      "         4.5239e-01, 3.4863e-01, 6.2207e-01, 7.0801e-02, 4.8828e-04, 6.3770e-01,\n",
      "         2.0020e-01, 4.4281e-02, 3.5156e-01, 7.5256e-02, 5.9570e-02, 6.8408e-01,\n",
      "         5.8887e-01, 1.0278e-01, 4.2114e-01, 6.5625e-01, 6.8604e-02, 5.2881e-01,\n",
      "         2.5317e-01, 3.1128e-01, 4.1382e-02, 3.2056e-01, 3.8184e-01, 6.6602e-01,\n",
      "         2.8418e-01, 7.2119e-01, 5.7227e-01, 1.9043e-01, 5.6299e-01, 6.5820e-01,\n",
      "         6.7200e-02, 6.7200e-02, 4.4556e-01, 3.5376e-01, 4.1656e-02, 1.1481e-01,\n",
      "         9.7290e-02, 3.1836e-01, 3.9819e-01, 3.3539e-02, 2.0898e-01, 3.1079e-01,\n",
      "         3.4155e-01, 1.9788e-01, 2.1326e-01, 4.0820e-01, 6.5381e-01, 3.6694e-01,\n",
      "         3.2861e-01, 2.5415e-01, 1.9006e-01, 3.9209e-01, 6.7676e-01, 6.9238e-01,\n",
      "         1.8433e-01, 5.1123e-01, 6.2012e-02, 2.7539e-01, 5.2277e-02, 5.5566e-01,\n",
      "         2.0435e-01, 6.1572e-01, 1.1505e-01, 5.8545e-01, 6.1493e-02, 5.6689e-01,\n",
      "         2.1790e-01, 1.0605e-02, 6.2012e-01, 2.0337e-01, 1.4050e-01, 1.5625e-01,\n",
      "         1.9141e-01, 2.5488e-01, 3.1958e-01, 4.8315e-01, 5.9277e-01, 6.8701e-01,\n",
      "         2.2827e-01, 2.3303e-01, 4.8828e-04, 5.7910e-01, 4.1187e-01, 5.3613e-01,\n",
      "         2.6514e-01, 2.2095e-01, 3.3740e-01, 6.1865e-01, 4.6265e-01, 2.6514e-01,\n",
      "         7.1387e-01, 3.3020e-02, 3.9697e-01, 1.2305e-01, 5.6543e-01, 1.0834e-01,\n",
      "         2.4182e-01, 4.8828e-04, 2.9590e-01, 4.4556e-02, 5.0879e-01, 5.8496e-01,\n",
      "         5.3320e-01, 2.7573e-02, 5.4346e-01, 6.5857e-02, 5.4248e-01, 8.2214e-02,\n",
      "         5.8105e-01, 4.1992e-01, 5.0049e-01, 1.7136e-02, 3.9355e-01, 3.4009e-01,\n",
      "         3.4375e-01, 1.3477e-01, 3.0737e-01, 4.1650e-01, 9.4421e-02, 1.9983e-01,\n",
      "         2.6343e-01, 2.4377e-01]], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(a(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1c48e079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.0869e-01, 3.0933e-01, 8.8440e-02, 3.5791e-01, 7.2205e-02, 6.7041e-01,\n",
      "         4.5239e-01, 3.4863e-01, 6.2207e-01, 7.0801e-02, 4.8828e-04, 6.3770e-01,\n",
      "         2.0020e-01, 4.4281e-02, 3.5156e-01, 7.5256e-02, 5.9570e-02, 6.8408e-01,\n",
      "         5.8887e-01, 1.0278e-01, 4.2114e-01, 6.5625e-01, 6.8604e-02, 5.2881e-01,\n",
      "         2.5317e-01, 3.1128e-01, 4.1382e-02, 3.2056e-01, 3.8184e-01, 6.6602e-01,\n",
      "         2.8418e-01, 7.2119e-01, 5.7227e-01, 1.9043e-01, 5.6299e-01, 6.5820e-01,\n",
      "         6.7200e-02, 6.7200e-02, 4.4556e-01, 3.5376e-01, 4.1656e-02, 1.1481e-01,\n",
      "         9.7290e-02, 3.1836e-01, 3.9819e-01, 3.3539e-02, 2.0898e-01, 3.1079e-01,\n",
      "         3.4155e-01, 1.9788e-01, 2.1326e-01, 4.0820e-01, 6.5381e-01, 3.6694e-01,\n",
      "         3.2861e-01, 2.5415e-01, 1.9006e-01, 3.9209e-01, 6.7676e-01, 6.9238e-01,\n",
      "         1.8433e-01, 5.1123e-01, 6.2012e-02, 2.7539e-01, 5.2277e-02, 5.5566e-01,\n",
      "         2.0435e-01, 6.1572e-01, 1.1505e-01, 5.8545e-01, 6.1493e-02, 5.6689e-01,\n",
      "         2.1790e-01, 1.0605e-02, 6.2012e-01, 2.0337e-01, 1.4050e-01, 1.5625e-01,\n",
      "         1.9141e-01, 2.5488e-01, 3.1958e-01, 4.8315e-01, 5.9277e-01, 6.8701e-01,\n",
      "         2.2827e-01, 2.3303e-01, 4.8828e-04, 5.7910e-01, 4.1187e-01, 5.3613e-01,\n",
      "         2.6514e-01, 2.2095e-01, 3.3740e-01, 6.1865e-01, 4.6265e-01, 2.6514e-01,\n",
      "         7.1387e-01, 3.3020e-02, 3.9697e-01, 1.2305e-01, 5.6543e-01, 1.0834e-01,\n",
      "         2.4182e-01, 4.8828e-04, 2.9590e-01, 4.4556e-02, 5.0879e-01, 5.8496e-01,\n",
      "         5.3320e-01, 2.7573e-02, 5.4346e-01, 6.5857e-02, 5.4248e-01, 8.2214e-02,\n",
      "         5.8105e-01, 4.1992e-01, 5.0049e-01, 1.7136e-02, 3.9355e-01, 3.4009e-01,\n",
      "         3.4375e-01, 1.3477e-01, 3.0737e-01, 4.1650e-01, 9.4421e-02, 1.9983e-01,\n",
      "         2.6343e-01, 2.4377e-01]], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(a(data.to(torch.float32)).to(torch.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d8f3845c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0379, -0.0127, -0.0067,  ...,  0.0037, -0.0528,  0.0105],\n",
       "        [-0.0534, -0.0088,  0.0450,  ..., -0.0033, -0.0148,  0.0345],\n",
       "        [ 0.0424, -0.0146,  0.0022,  ...,  0.0226,  0.0007,  0.0328],\n",
       "        ...,\n",
       "        [-0.0692,  0.0705, -0.0648,  ...,  0.0278, -0.0333,  0.0130],\n",
       "        [ 0.0017,  0.0330, -0.0479,  ..., -0.0121, -0.0211,  0.0172],\n",
       "        [-0.0619, -0.0010, -0.0347,  ...,  0.0504,  0.0083, -0.0307]],\n",
       "       device='cuda:0', dtype=torch.float16, requires_grad=True)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd28571e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.1206e-05, -3.1590e-06,  3.6955e-06,  ..., -8.5235e-06,\n",
       "          3.6359e-06, -2.0862e-06],\n",
       "        [-1.7986e-03,  3.9062e-03, -6.9847e-03,  ...,  2.5768e-03,\n",
       "          9.1970e-05, -6.0692e-03],\n",
       "        [-5.0316e-03,  7.6675e-03, -6.0577e-03,  ...,  2.5234e-03,\n",
       "          5.1003e-03,  1.9318e-02],\n",
       "        ...,\n",
       "        [-2.4429e-02,  8.8272e-03,  2.4139e-02,  ..., -1.1566e-02,\n",
       "         -1.3702e-02, -4.4746e-03],\n",
       "        [-3.7781e-02,  5.1193e-03,  1.3397e-02,  ...,  1.5327e-02,\n",
       "         -8.6136e-03, -3.2806e-02],\n",
       "        [-2.7588e-02,  1.2939e-02, -8.2397e-03,  ...,  8.6746e-03,\n",
       "          1.4412e-02,  1.1208e-02]], device='cuda:0', dtype=torch.float16,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.model.embed_tokens.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c2a288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
